---
title: "Random Forest Analysis of Heart Failure Dataset"
author: "Tim Leschke, Pamela Mishaw, Sierra Landacre, Pallak Singh "
format: 
  revealjs:
    smaller: true
    theme: serif
course: STA 6257 - Advanced Statistical Modeling
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

## Random Forest

-   Random Forest is a promising machine learning model because it
    correctly classifies data from large data sets, is resistant to
    outliers, and is easy to use.
-   Random Forest is a group of decision trees (a forest) that are
    created from identically distributed, independent random samples of
    data drawn with replacement from the original dataset [@breiman].

## Methods

::: columns
::: {.column width="60%"}
![](SingleTree.png){fig-align="left"}

-   single classification tree.
:::

::: {.column width="40%"}
![](images/rf%20fig%201-01.png){fig-align="right"}

-   Random Forest uses multiple classification trees.
:::
:::

## Methods

::: panel-tabset
### Random Forest Algorithm

![](images/RF%20Algorith.png){fig-align="center"}

### Formulas

::: columns
::: {.column width="50%"}
The <em>Gini Index</em> is referred to as a measure of node purity
[@james]. It can also be used to measure the importance of each
predictor. The Gini Index is defined by the following formula where K is
the number of classes and ${\hat{p}_{mk}}$ is the proportion of
observations in the <em>m</em>th region that are from the <em>k</em>th
class. A Gini Index of 0 represents perfect purity.

$$D=-\sum_{n=1}^{K} {\hat{p}_{mk}}(1-\hat{p}_{mk})$$
:::

::: {.column width="50%"}
<em>Bagging</em> is the aggregation of the results from each decision
tree. It is defined by the following formula where B is the number of
training sets and $\hat{f}^{*b}$ is the prediction model. Although
bagging improves prediction accuracy, it makes interpreting the results
harder as they cannot be visualized as easily as a single decision tree
[@james].

$${\hat{f}bag(x) = 1/B \sum_{b=1}^{B}\hat{f}^{*b}(x)}$$
:::
:::
:::

## Analysis and Results

> -   We ingest the data into R-Studio
> -   Perform classification with Random Forest
> -   Perform analysis

## Data Used

::: panel-tabset
### Heart Failure Table

![](images/HF%20Table.png){fig-align="center" width="70%"}

### Dataset Information

-   The dataset comes from the Faisalabad Institute of Cardiology and
    the Allied Hospital in Faisalabad Pakistan.
-   There are 299 patient records with 13 features per record.
-   Random Forest model used for predicting heart failure events for
    patients.

![](FaisalabadLogo.png){fig-align="center"}
:::

## Model Evaluation Metrics

Various metrics are used to assess the Random Forest model performance:

> -   Out of Bag error rate/accuracy - OOB data is data left unused by a
>     decision tree.
> -   Confusion Matrix - shows True Positive, False Positive, False
>     Negative and True Negative values to support performance
>     evaluation
> -   Precision - also known as <em>sensitivity</em> and it represents
>     how many observations labeled positive are actually positive.
> -   Recall - quantifies how many positive observations are actually
>     predicted as positive.
> -   F1 - harmonic mean of the precision and recall; assesses
>     predictive performance.
> -   Balanced accuracy - average accuracy of both true-positive and
>     true-negative classes.
> -   AUC-ROC - area under a curve created by the true positive rate vs.
>     false positive rate.

## Variable Importance Plot

![](VariableImportancePlot.png){fig-align="center"}

## FourFold Plot (Confusion Matrix)

![](FourFoldPlot.png){fig-align="center"}

## Confusion Matrix Heatmap

![](ConfusionMatrixHeatmap.png){fig-align="center"}

## Variable Correlation Heatmap

![](VariableCorrelationHeatmap.png){fig-align="center"}

## ROC - Default Values

![](DefaultROC.png){fig-align="center"}

## trainControl() - Random Selection

![](TrainControl_RandomSelection.png){fig-align="center"}

## trainControl() - Grid Search

![](TrainControl_GridSearch.png){fig-align="center"}

## Variable Importance Plot - Tuned

![](VariableImportancePlot_tuned.png){fig-align="center"}

## FourFold Plot (Confusion Matrix)

![](FourFoldPlot_tuned.png){fig-align="center"}

## Kappa Plot

![](KappaPlot.png){fig-align="center"}

## Tuned vs. Default ROC

![](TunedROC.png){fig-align="center"}

## Model Results

::: columns
::: {.column width="60%"}
![](images/data.png)
:::

::: {.column width="40%"}
-   The testing accuracies of both models are slightly lower than their
    respective training accuracies which indicates overfitting of the
    training dataset.
-   The performance of model 2 is better than model 1. This is based off
    of the modelâ€™s training and testing accuracies; precision; F1; and
    balanced accuracy as they are all higher than those of the default
    model.
:::
:::

## Conclusion

## Software and Hardware Configuration

-   RStudio Pro 2023.12.0, Build 369.pro3
-   Various R libraries
-   RStudio Server running on RHEL9 based virtual machine within a
    VMware VSphere HA cluster. The VM has 50 vCPU's and 196 GB ram
    assigned
-   Hardware includes Dell PowerEdge R750 servers with Dual Xeon Gold
    6338N (32 core) CPUs, 512 GB RAM, and sfp28 25 gbit networking for
    all communications
-   Cluster storage is from an NVMe based Dell SAN.

## References
