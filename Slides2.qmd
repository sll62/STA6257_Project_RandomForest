---
title: "Random Forest Analysis of Heart Failure Dataset"
author: "Tim Leschke, Pamela Mishaw, Sierra Landacre, Pallak Singh "
format: 
  revealjs:
    smaller: true
    theme: serif
course: STA 6257 - Advanced Statistical Modeling
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

## Random Forest

-   Random Forest is a promising machine learning model because it
    correctly classifies data from large data sets, is resistant to
    outliers, and is easy to use.
-   Random Forest is a group of decision trees (a forest) that are
    created from identically distributed, independent random samples of
    data drawn with replacement from the original dataset (Breiman
    2001).

## Methods

::: panel-tabset
### Random Forest Algorithm

![](images/RF Algorith.png){fig-align="center"}

### Generation of a Random Forest

::: columns
::: {.column width="60%"}
![](images/rf fig 1.png){fig-align="left"}
:::

::: {.column width="40%"}
-   Figure 1 shows the generation of a Random Forest. The uniqueness of
    each tree, as a result of random data samples, allows the ensemble
    to avoid misclassification, and improve classification accuracy.
:::
:::

### 

### Formulas

::: columns
::: {.column width="50%"}
The <em>Gini Index</em> is referred to as a measure of node purity
[@james]. It can also be used to measure the importance of each
predictor. The Gini Index is defined by the following formula where K is
the number of classes and ${\hat{p}_{mk}}$ is the proportion of
observations in the <em>m</em>th region that are from the <em>k</em>th
class. A Gini Index of 0 represents perfect purity.

$$D=-\sum_{n=1}^{K} {\hat{p}_{mk}}(1-\hat{p}_{mk})$$
:::

::: {.column width="50%"}
<em>Bagging</em> is the aggregation of the results from each decision
tree. It is defined by the following formula where B is the number of
training sets and $\hat{f}^{*b}$ is the prediction model. Although
bagging improves prediction accuracy, it makes interpreting the results
harder as they cannot be visualized as easily as a single decision tree
[@james].

$${\hat{f}bag(x) = 1/B \sum_{b=1}^{B}\hat{f}^{*b}(x)}$$
:::
:::
:::

## Data Used

::: panel-tabset
### Heart Failure Table

![](images/HF%20Table.png){fig-align="center" width="70%"}

### Dataset Information

-   The dataset comes from the Faisalabad Institute of Cardiology and
    the Allied Hospital in Faisalabad Pakistan and consists of the
    medical records of 299 patients who experienced heart failure
    [@chicco2020machine].
-   There are 299 patient records with 13 features per record.
-   We use this dataset to create and evaluate a Random Forest model
    used for predicting heart failure events for patients.
:::

## Model Evaluation Metrics

::: panel-tabset
### OOB error rate/accuracy

-   The Out-of-Bag data is the data left unused by an individual
    predictor (decision tree) after a bootstrap sample is taken from the
    original data set.
-   The OOB data is used for internal validation– the prediction error
    rate is taken after running the “unseen” data through each tree and
    averaged to provide the overall OOB error rate. (Breiman 2001)

### Confusion Matrix

::: incremental
-   Shows the values of True Negative, False Negative, False Positive,
    and True Positive predictions produced by a model.
-   Precision: This metric quantifies how many of the observations
    labeled as positive are actually positive (Raschka, Liu, and
    Mirjalili 2022).
-   Recall: It quantifies how many of the positive observations have
    been predicted as positive (Raschka, Liu, and Mirjalili 2022).
-   F1 Score: Is the harmonic mean of the precision and recall and so
    used to assess predictive performance. (Raschka, Liu, and Mirjalili
    2022).
-   Balanced Accuracy: Aids in reducing the effects of class imbalance
    in the data set so that accuracy of predicting the dominant class
    does not conceal the classification accuracy for the minority class
    (Brodersen et al. 2010).
:::

### AUC-ROC

-   Area under the receiver operating characteristic curve.
-   This is the model’s true positive rate (on the Y-axis) is plotted
    against the false positive rate (on the X-axis) using varying
    classification thresholds (Huang and Ling 2005).
:::

## Model Results

::: columns
::: {.column width="60%"}
![](images/data.png)
:::

::: {.column width="40%"}
-   The testing accuracies of both models are slightly lower than their
    respective training accuracies which indicates overfitting of the
    training dataset.
-   The performance of model 2 is better than model 1. This is based off
    of the model’s training and testing accuracies; precision; F1; and
    balanced accuracy as they are all higher than those of the default
    model.
:::
:::
## References 